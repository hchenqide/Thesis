\chapter{Experiments}

This chapter presents the experiments conducted on MiniSatUP and its integration with cvc5. We performed correctness testing by a fuzzer implemented for IPASIR-UP as well as cvc5 regression tests and fixed bugs during development, and we also conducted performance testing on cvc5 after the intergration, which demonstrates no measurable performance overhead with introducing IPASIR-UP.

\section{Correctness}

% overview
In developing a program for tasks like formal verification of hardware and software, its own correctness and robustness is essential. Proof outputs are often required for such a verification software for correctness checking by third-party proof checkers. Testing techniques like assertions, fuzzing and regression tests are often employed in the development of such software. In the testing for MiniSatUP and cvc5 we also used such techniques.

% fuzzing
Fuzzing is an automated testing technique that generates a large number of random and potentially adversarial input data to uncover bugs, crashes, or unexpected behavior in software. In this work, a fuzzer for the IPASIR-UP interface is developed during implementation of MiniSatUP before its integration in cvc5, to ensure a full achievement to the functionality of the interface as well as its correctness.

% minisat fuzzer
%% connection
The main fuzzer takes a CNF file as input, and splits the clauses into two parts, with the first part given to the solver initially, and the rest added via IPASIR-UP interface. A \code{UserPropagator} implementing IPASIR-UP interfaces will be given to the solver via \code{connect_user_propagator} for it to interact with.

%% fuzzing script
A fuzzing script is written to generate random CNF files, run the fuzzer with the CNF file, and check model or the proof output of the fuzzer. We use CNFuzz \cite{BrummayerLonsingBiere-SAT10} to generate a CNF with a random seed, and DRUP checker \cite{6679408} to check the proof output in DRUP format. The check model part when result is SAT is implemented in the main fuzzer right after solving. We supported DRUP proof output to MiniSatUP to enable DRUP checking, which basically prints the clause to the proof file whenever a new clause is generated and an old clause is deleted. If the solve result is UNSAT, the DRUP checker checks the proof file against the original CNF file and report possible failures. The shell script is run continuously to uncover possibly more bugs.

The main fuzzer contains around 300 lines of C++ code including parsing CNF file, where the \code{UserPropagator} class implementation takes around 150 lines of code. The fuzzing shell script contains around 50 lines of code.

%% external clause
Adding an external clause is first implemented by the fuzzer. On each interaction, if there is a next external clause available and with a certain probability, the clause will be provided. We also inserted statistics and assertions on each case when adding an external clause, to ensures all cases when adding an external clauses is hit and tested, and to inspect any possible error. An example statistics table counting how many times each case is hit with a random input is shown in table \ref{tab:stats}.

\begin{table}[h!]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
    & \multicolumn{3}{c|}{\textbf{input CNF with different seeds}} \\
    \cline{2-4}
    \textbf{cases adding external clause} & \textbf{675958302} & \textbf{872113057} & \textbf{367451228} \\
    \hline
    unsat & 0 & 1 & 0 \\
    skipped & 57 & 0 & 34 \\
    unit & 2 & 5 & 4 \\
    two watching literals & 3502 & 4009 & 1828 \\
    \quad false,false & 6 & 6 & 4 \\
    \quad\quad conflict & 1 & 0 & 2 \\
    \quad\quad propagation & 5 & 6 & 2 \\
    \quad undef,false & 39 & 77 & 25 \\
    \quad undef,undef & 2483 & 2666 & 1229 \\
    \quad true,false & 16 & 19 & 17 \\
    \quad\quad propagation & 6 & 7 & 8 \\
    \quad\quad no propagation & 10 & 12 & 9 \\
    \quad true,undef & 636 & 826 & 364 \\
    \quad true,true & 322 & 415 & 189 \\
    \hline
    \textbf{variable count} & 513 & 591 & 247 \\
    \textbf{clause count} & 3956 & 4629 & 2699 \\
    \textbf{result} & SAT & UNSAT & UNSAT \\
    \hline
  \end{tabular}
  \caption{statistics of cases hit adding external clause with different input}
  \label{tab:stats}
\end{table}

\code{cb_check_found_model} is also implemented by checking if there are still clauses left to be added, and if all clauses are satisfied by current assignments.

%% early bugs
At this stage, a wrong assertion to a case of possible states for the 2-watching literals is discovered and fixed. And a bug in clause sorting predicate which leads to undesired order of the two watching literals is also found by an assertion error during fuzzing. Another issue related with the timing of connecting user propagator to the solver is discovered and fixed, where the clauses are added to the solver before connecting to user propagator and therefore some instant assignments from unit clauses are not informed to the user propagator leading to incorrect model. Batch notification of assignments is later implemented and more assertions on connecting user propagators are added.

%% external propagation and lazy propagation
Next, the lazy propagation interface is implemented. The \code{UserPropagator} checks if the next clause to be added actually leads to propagation based on the current notified assignments. When the clause only contains false literals but one unassigned literal, the implied literal is returned to the sat solver for propagation, while the clause is saved in a map indexed by the propagated literal and can be retrieved from the literal during lazy explaination. Other clauses are still added normally though the \code{cb_has_external_clause} and \code{cb_add_external_clause_lit} callbacks. When a backtrack happens, the entries in the map whose literals are unassigned will be removed from the map and added back to the set of remaining clauses.

The case when the propagated literal is a root-level unit was intentionally avoided in fuzzer initially, because the machanism of breaking the conflict analysis and re-propagate in the correct level was not yet invented. Still it is possible that a lazily added clause may introduce a lower actual level of the literal than its assigned leven, thus breaking the invariant of 2-watching scheme, but this case wouldn't cause error in the program, only possible performance issues. A map from literal to the level of its assignment is kept in fuzzer, so as to check if the next clause that generates a propagation is actually root-level propagation, and if so,

% cvc5 make check and bugs after cvc5 integration
This fuzzer has helped discovering bugs in MiniSatUP especially for adding external clauses and external propagations interfaces. But it doesn't cover the interfaces like decisions and assumptions, as implementing such interfaces are not straightforward without an actual user application. After integrated with cvc5, these interfaces are fully tested with a few more bugs discovered and fixed.

With thousands of the regression test cases from cvc5, which are still evolving along with the development, we are able to test cvc5 by running the \code{make check} command after building cvc5 integrated with MiniSatUP. And several more bugs from MiniSatUP has been discovered. Also a bug within cvc5 and a bug in CaDiCaL are discovered and fixed from comparison of test results.

Before integration with cvc5, the compiler flag \code{-fsanitize=address} has also been enabled in MiniSatUP to prevent possible memory leaks, and during fuzzing and testing no memory leak has happened. This flag is removed during integration because it's not compatible with current cvc5 builds, and removing this flag causes a bug in the fuzzer to appear, where during external propagation \code{clauses.front()} is called without first checking if \code{clauses} is empty.

\todo{the cvc5 bug and the cadical bug}

In a final running of \code{make check} of cvc5, an unfinished case is identified to be due to the missing implementation of \code{Terminator} from CaDiCaL interface, thus exhibiting different behavior as with CaDiCaL. But so far, the \code{make check} command still woundn't pass completely due to several unfinished cases that eventually timeout. These cases still need to be examined.

% bug classificaiton by severity, difficulty to find/fix
All bugs are listed in the table below as summarized:

\todo{table of all bugs}

\section{Performance Testing}

% benchmarks

We performed performance test on cvc5 with the dataset.

% result and comparison with cadical/minisat

no discrepancy occurred
